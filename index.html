<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="description"
    content="Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy">
    <meta name="keywords" content="Natural Language, Formal Method, Multi-Robots">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy</title>
    
    <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-FV4ZJ9PVSV"></script>   -->
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        
        gtag('config', 'G-FV4ZJ9PVSV');
    </script>
    
    
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
    rel="stylesheet">
    
    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
    
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            },
            svg: {
                fontCache: 'global'
            }
        };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
</head>
<body>
    
    <section class="hero">
        <div class="hero-body">
            <div class="container is-fullhd">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy</h1>
                        <!-- <h3 class="title is-4 conference-authors"><a target="_blank" href="https://www.corl2023.org/">CoRL 2023 (Oral)</a></h3> -->
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a target="_blank" href="">Anonymous Authors</a>
                            </span>
                            <!-- <span class="author-block">
                                <a target="_blank" href="https://scholar.google.com/citations?user=V22j1C0AAAAJ&hl=zh-CN&oi=sra/">Tianhao Wei</a><sup>*,1</sup>,
                            </span>
                            <span class="author-block">
                                <a target="_blank" href="">Liqian Ma</a><sup>*,1,2</sup>,
                            </span>
                            <span class="author-block">
                                <a target="_blank" href="https://ruichen.pub/">Rui Chen</a><sup>1</sup>,
                            </span>
                            <span class="author-block">
                                <a target="_blank" href="https://scholar.google.com/citations?user=P-79KOcAAAAJ&hl=en">Weiye Zhao</a><sup>1</sup>,
                            </span>
                            <span class="author-block">
                                <a target="_blank" href="https://www.cs.cmu.edu/~cliu6/">Changliu Liu</a><sup>1</sup>,
                            </span> -->
                        </div>
                        
                        <!-- <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>*</sup>Equal Contribution,</span>
                            <span class="author-block"><sup>1</sup>Carnegie Mellon University,</span>
                            <span class="author-block"><sup>2</sup>Tsinghua University</span> <br>
                        </div> -->
                        
                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- PDF Link. -->
                                <span class="link-block">
                                    <a target="_blank" href="xxx.pdf"
                                    class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <i class="fas fa-file-pdf"></i>
                                    </span>
                                    <span>Paper (Coming soon)</span>
                                </a>
                            </span>
                            
                            <!-- Arxiv Link. -->
                            <!-- <span class="link-block">
                                <a target="_blank" href="https://arxiv.org/abs/2307.05973333333333"
                                class="external-link button is-normal is-rounded is-dark">
                                <span class="icon">
                                    <i class="fas fa-file"></i>
                                </span>
                                <span>ArXiv</span>
                            </a>
                        </span> -->
                        
                        <!-- Video Link. -->
                        <!-- <span class="link-block">
                            <a target="_blank" href="https://youtu.be/Yvn4eR05A3M"
                            class="external-link button is-normal is-rounded is-dark">
                            <span class="icon">
                                <i class="fab fa-youtube"></i>
                            </span>
                            <span>Video</span>
                        </a>
                    </span> -->
                    
                    <!-- Code Link. -->
                    <span class="link-block">
                        <a target="_blank" href="https://github.com/"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                            <i class="fab fa-github"></i>
                        </span>
                        <span>Code (Coming soon)</span>
                    </a>
                </span>
            </div>
        </div>
    </div>
</div>
</div>
</div>
</section>

<section class="section">
    <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        Long-horizon planning in robotics is often hindered by challenges such as uncertainty accumulation, computational complexity, delayed rewards and incomplete information. 
                        This work proposes an innovative approach to exploit the inherent task hierarchy from human instructions to facilitate multi-robot planning. 
                        Using Large Language Models (LLMs), we propose a two-step approach to translate multi-sentence human instructions into a structured language, 
                        Hierarchical Linear Temporal Logic (LTL), which serves as an intermediary formal representation for planning.
                        Initially, LLMs transform the human instructions into a Hierarchical Task Network-like representation, defined as Hierarchical Task Tree, 
                        capturing the logical and temporal relations among tasks.
                        Following this, a domain-specific fine-tuning of LLM translates sub-tasks of each task into flat LTL formulas, 
                        aggregating them to form hierarchical LTL specifications. 
                        These specifications are then leveraged for planning using off-the-shelf planners.
                        Our framework not only bridges the gap between human instructions and algorithmic planning 
                        but also showcases the potential of LLMs in harnessing human-like hierarchical reasoning to automate 
                        complex task planning for multiple robots. Through evaluations in both simulation and real-world 
                        experiments involving human participants, we demonstrate that our method can handle more complex human 
                        instructions compared to existing methods. The results indicate that our approach achieves higher success 
                        rates and lower costs in multi-robot task allocation and plan generation.
                    </p>
                </div>
            </div>
        </div>
        <!--/ Abstract. -->
        
    </div>
    
    <!-- Paper video. -->
    <br>
    <br>
    
    <!-- <div class="container is-max-widescreen">
        
        <div class="rows">
            <h2 class="title is-3">Video</h2>
            <div class="publication-video">
                <iframe src="https://www.youtube.com/embed/Yvn4eR05A3M"
                frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </div>
        </div>
    </div> -->
    
</section>


<section class="section">
    <div class="container is-max-widescreen">
        
        <div class="rows">
            
            
            <!-- Animation. -->
            <div class="rows is-centered ">
                <div class="row is-full-width">
                    <h2 class="title is-3"><span class="dperact">Overview</span> </h2>
                    
                    <!-- Interpolating. -->
                    <div class="content has-text-justified">
                        <!-- <br> -->
                    </div>
                    <img src="media/figures/overview.png" class="interpolation-image" />
                </br>
            </br>
            <p class="content has-text-justified">
                Overview of the framework, using the dishwasher loading problem as a case study. Note that the non-leaf nodes in the HTT, the language descriptions of sibling tasks, and the flat specifications are color-coded to indicate one-to-one correspondence.
            </p>
            
        </br>
    <!--/ Re-rendering. -->
</div>
</div>
</section>

<footer class="footer">
    <div class="container">
        <div class="columns is-centered">
            <div class="column">
                <div class="content has-text-centered">
                    <p>
                        Website template borrowed from <a href="https://github.com/nerfies/nerfies.github.io">NeRFies</a> and <a href="https://voxposer.github.io/">VoxPoser</a>. 
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>

</body>
</html>

